{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/main/Desktop/LSTM_Forecast/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/main/Desktop/LSTM_Forecast'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from TimeSeriesForecast import logger\n",
    "from TimeSeriesForecast.utils.common import read_yaml,create_directories\n",
    "from TimeSeriesForecast.constants import *\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from notebooks.src.functions_torch import TimeSeries\n",
    "from notebooks.src.functions_torch import LSTM\n",
    "# from notebooks.src.functions_torch import set_seed\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    save_path: Path\n",
    "    model_name: Path\n",
    "    n_steps: int\n",
    "    split_ratio: float\n",
    "    seed: int\n",
    "    drop_out_rate: float\n",
    "    input_size: int\n",
    "    hidden_size: int\n",
    "    num_stacked_layers: int\n",
    "    learning_rate: float\n",
    "    num_epochs: int\n",
    "    batch_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath= CONFIG_FILE_PATH,\n",
    "                 params_filepath= PARAMS_FILE_PATH,\n",
    "                 schema_filepath= SCHEMA_FILE_PATH):\n",
    "        \n",
    "        self.config= read_yaml(config_filepath)\n",
    "        self.params= read_yaml(params_filepath)\n",
    "        self.schema= read_yaml(schema_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def model_trainer_config(self)->ModelTrainerConfig:\n",
    "        config= self.config.model_trainer\n",
    "        params= self.params.TorchModel\n",
    "        schema= self.schema\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "                \n",
    "        model_trainer_config= ModelTrainerConfig(\n",
    "                                                root_dir= config.root_dir,\n",
    "                                                data_path= config.data_path,\n",
    "                                                save_path= config.save_path,\n",
    "                                                model_name= config.model_name,\n",
    "                                                n_steps= params.n_steps,\n",
    "                                                split_ratio= params.split_ratio,\n",
    "                                                seed= params.seed,\n",
    "                                                drop_out_rate= params.drop_out_rate,\n",
    "                                                input_size= params.input_size,\n",
    "                                                hidden_size= params.hidden_size,\n",
    "                                                num_stacked_layers= params.num_stacked_layers,\n",
    "                                                learning_rate= params.learning_rate,\n",
    "                                                num_epochs= params.num_epochs,\n",
    "                                                batch_size= params.batch_size\n",
    "                                                )\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self,config:ModelTrainerConfig):\n",
    "        self.config= config\n",
    "        self.tensor= None\n",
    "        self.X_train= None\n",
    "        self.X_test= None\n",
    "        self.y_train= None\n",
    "        self.y_test= None\n",
    "    def tensor_loader(self):\n",
    "        torch.manual_seed(self.config.seed)\n",
    "        torch.cuda.manual_seed(self.config.seed)\n",
    "        np.random.seed(self.config.seed)\n",
    "        try:\n",
    "            self.tensor= torch.load(self.config.data_path)\n",
    "            self.X_train,self.X_test,self.y_train,self.y_test = self.tensor['X_train'],self.tensor['X_test'],\\\n",
    "                                                                self.tensor['y_train'],self.tensor['y_test']\n",
    "            return self\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Problem loading the tensors: {e}')\n",
    "    def time_series_dataset(self):\n",
    "        try:\n",
    "            self.train_dataset= TimeSeries(self.X_train,self.y_train)\n",
    "            self.test_dataset= TimeSeries(self.X_test,self.y_test)\n",
    "            \n",
    "            self.train_loader= DataLoader(self.train_dataset,batch_size=self.config.batch_size,shuffle=True)\n",
    "            self.test_loader= DataLoader(self.test_dataset,batch_size=self.config.batch_size,shuffle=False)\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Problem the class modules {e}')\n",
    "        return self\n",
    "    \n",
    "    def training_torch(self):\n",
    "        try:\n",
    "            torch.manual_seed(self.config.seed)\n",
    "            torch.cuda.manual_seed(self.config.seed)\n",
    "            np.random.seed(self.config.seed)\n",
    "            device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "            model= LSTM(self.config.input_size,self.config.hidden_size,self.config.num_stacked_layers)\n",
    "            model.to(device)\n",
    "            loss_function = nn.MSELoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=self.config.learning_rate)\n",
    "            \n",
    "            for epoch in range(self.config.num_epochs):\n",
    "                model.train(True)\n",
    "                running_loss = 0.0\n",
    "\n",
    "                for _, batch in enumerate(self.train_loader):\n",
    "                    x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "                    output = model(x_batch)\n",
    "                    loss = loss_function(output, y_batch)\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    avg_train_loss= running_loss/len(self.train_loader)\n",
    "                    torch.save(model,self.config.save_path)\n",
    "                print(f'Epoch {epoch+1}/{self.config.num_epochs}, Train Loss: {avg_train_loss}')\n",
    "                logger.info(f'Train loss from Torch Model{avg_train_loss}')\n",
    "            torch.save(model,self.config.save_path)\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Problem training the model {e}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-06 12:26:23,135:INFO:common:yaml file: config/config.yaml loaded successfully]\n",
      "[2024-08-06 12:26:23,138:INFO:common:yaml file: params.yaml loaded successfully]\n",
      "[2024-08-06 12:26:23,140:INFO:common:yaml file: schema.yaml loaded successfully]\n",
      "[2024-08-06 12:26:23,141:INFO:common:created directory at: artifacts]\n",
      "[2024-08-06 12:26:23,142:INFO:common:created directory at: artifacts/model_trainer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/main/Desktop/LSTM_Forecast/time/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1992187452163886\n",
      "[2024-08-06 12:26:23,864:INFO:429443308:Train loss from Torch Model0.1992187452163886]\n",
      "Epoch 2/10, Train Loss: 0.13584739416414363\n",
      "[2024-08-06 12:26:23,972:INFO:429443308:Train loss from Torch Model0.13584739416414363]\n",
      "Epoch 3/10, Train Loss: 0.10072631147605451\n",
      "[2024-08-06 12:26:24,081:INFO:429443308:Train loss from Torch Model0.10072631147605451]\n",
      "Epoch 4/10, Train Loss: 0.06948442103616385\n",
      "[2024-08-06 12:26:24,192:INFO:429443308:Train loss from Torch Model0.06948442103616385]\n",
      "Epoch 5/10, Train Loss: 0.04388478030027314\n",
      "[2024-08-06 12:26:24,303:INFO:429443308:Train loss from Torch Model0.04388478030027314]\n",
      "Epoch 6/10, Train Loss: 0.02234303987841651\n",
      "[2024-08-06 12:26:24,422:INFO:429443308:Train loss from Torch Model0.02234303987841651]\n",
      "Epoch 7/10, Train Loss: 0.011270751882958311\n",
      "[2024-08-06 12:26:24,537:INFO:429443308:Train loss from Torch Model0.011270751882958311]\n",
      "Epoch 8/10, Train Loss: 0.006724874752850693\n",
      "[2024-08-06 12:26:24,646:INFO:429443308:Train loss from Torch Model0.006724874752850693]\n",
      "Epoch 9/10, Train Loss: 0.005594968679361045\n",
      "[2024-08-06 12:26:24,753:INFO:429443308:Train loss from Torch Model0.005594968679361045]\n",
      "Epoch 10/10, Train Loss: 0.005322136733659797\n",
      "[2024-08-06 12:26:24,861:INFO:429443308:Train loss from Torch Model0.005322136733659797]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "        config= ConfigurationManager()\n",
    "        model_trainer= config.model_trainer_config()\n",
    "        model_t= ModelTrainer(config=model_trainer)\n",
    "        model_t.tensor_loader()\n",
    "        model_t.time_series_dataset()\n",
    "        model_t.training_torch()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
